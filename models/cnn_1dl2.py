# -*- coding: utf-8 -*-
"""CNN_1DL2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pCYSShx3oVRQrinl9Nz21uiHFSD62edf
"""

#modelo CNN 1D con l2

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2  # Importar la funci√≥n de regularizaci√≥n L2
from sklearn.metrics import accuracy_score, f1_score
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
from models.metrics import metrics_values
import os
import joblib
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf


def grafico_perdida(history):
    plt.figure(figsize=(12, 4))

    # P√©rdida
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='P√©rdida de Entrenamiento')
    plt.plot(history.history['val_loss'], label='P√©rdida de Validaci√≥n')
    plt.title('P√©rdida durante el Entrenamiento')
    plt.xlabel('√âpocas')
    plt.ylabel('P√©rdida')
    plt.legend()

    # Precisi√≥n
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Precisi√≥n de Entrenamiento')
    plt.plot(history.history['val_accuracy'], label='Precisi√≥n de Validaci√≥n')
    plt.title('Precisi√≥n durante el Entrenamiento')
    plt.xlabel('√âpocas')
    plt.ylabel('Precisi√≥n')
    plt.legend()

    plt.tight_layout()
    plt.show()


def modelo_cnn_1DL2(data_path="src/", models_path="models/", epochs=50, batch_size=32):
    # üì¶ Cargar datos de entrenamiento y prueba
    x_train, y_train, feature_names = joblib.load(os.path.join(data_path, "train.pkl"))
    x_test, y_test, feature_names = joblib.load(os.path.join(data_path, "test.pkl"))

    # üîÅ Aplanar entradas si est√°n expandidas (para audio)
    if len(x_train.shape) > 2:
        x_train = x_train.reshape(x_train.shape[0], -1)
        x_test = x_test.reshape(x_test.shape[0], -1)

        # Add channel dimension for CNN 1D
    x_train = np.expand_dims(x_train, axis=-1)
    x_test = np.expand_dims(x_test, axis=-1)

    # üè∑Ô∏è Cargar nombres de clases (emociones)
    class_labels_path = os.path.join(data_path, "class_labels.npy")
    if os.path.exists(class_labels_path):
        class_names = np.load(class_labels_path, allow_pickle=True)
    else:
        raise FileNotFoundError("‚ùå No se encontr√≥ el archivo class_labels.npy con los nombres de las emociones.")

    # üîÑ Decodificar etiquetas One-Hot a √≠ndices
    y_train_labels = np.argmax(y_train, axis=1)
    y_test_labels = np.argmax(y_test, axis=1)


    model = Sequential()
    model.add(Conv1D(32, 3, activation='relu', input_shape=(x_train.shape[1], 1), kernel_regularizer=l2(0.01)))  # L2 regularization
    model.add(MaxPooling1D(2))
    model.add(Conv1D(64, 3, activation='relu', kernel_regularizer=l2(0.0001)))  # L2 regularization
    model.add(MaxPooling1D(2))
    model.add(Conv1D(128, 3, activation='relu', kernel_regularizer=l2(0.0001)))  # L2 regularization
    model.add(MaxPooling1D(2))
    model.add(Flatten())
    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))  # L2 regularization
    model.add(Dropout(0.6))  # Aumentar dropout
    model.add(Dense(6, activation='softmax'))  # Cambiado a 6 para coincidir con el n√∫mero de clases en y_train_balanced

    # Resumen del modelo
    model.summary()

    # Compilar el modelo
    model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])

    # Definir callbacks
    early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)
    lr_reduction = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)

    # Entrenar el modelo
    history = model.fit(x_train, y_train,
                            validation_data=(x_test, y_test),
                            epochs=epochs,
                            batch_size=batch_size,
                            verbose=1,
                            callbacks=[early_stopping, lr_reduction])



    # Visualizaci√≥n de la p√©rdida y precisi√≥n
    grafico_perdida(history)

    # üíæ Guardar modelo
    model_path = os.path.join(models_path, "cnn1d2L.keras")
    model.save(model_path)
    print(f"üì¶ Modelo CNN1D2L guardado en: {model_path}")

    # Evaluate the model
    accuracy = model.evaluate(x_test, y_test)[1] * 100 # Use x_test directly
    print(f"Accuracy of our model on test data: {accuracy:.2f} %")

    # üß™ Evaluaci√≥n en test
    y_pred_probs = model.predict(x_test)
    y_pred_labels = np.argmax(y_pred_probs, axis=1)
    #y_test_labels = np.argmax(y_test, axis=1) # Already created y_test_labels earlier

    print("üìà Evaluaci√≥n final en conjunto de prueba:")
    metrics_values(y_test_labels, y_pred_labels, class_names)

    return model, x_test, feature_names # Return model, x_test, and feature_names
