# -*- coding: utf-8 -*-
"""CNN1D.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FQjyZAhT42ZMtXo4Y_Fn4mvAGo6e6oH6
"""



"""nuevo modelo CNN 1D"""

# Importaci√≥n de librer√≠as necesarias
import os
import joblib
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam

def grafico_perdida(history):
    plt.figure(figsize=(12, 4))

    # P√©rdida
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='P√©rdida de Entrenamiento')
    plt.plot(history.history['val_loss'], label='P√©rdida de Validaci√≥n')
    plt.title('P√©rdida durante el Entrenamiento')
    plt.xlabel('√âpocas')
    plt.ylabel('P√©rdida')
    plt.legend()

    # Precisi√≥n
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Precisi√≥n de Entrenamiento')
    plt.plot(history.history['val_accuracy'], label='Precisi√≥n de Validaci√≥n')
    plt.title('Precisi√≥n durante el Entrenamiento')
    plt.xlabel('√âpocas')
    plt.ylabel('Precisi√≥n')
    plt.legend()

    plt.tight_layout()
    plt.show()


def modelo_cnn_1D(data_path="src/", models_path="models/", epochs=50, batch_size=32):
    # üì¶ Cargar datos de entrenamiento y prueba
    x_train, y_train, feature_names = joblib.load(os.path.join(data_path, "train.pkl"))
    x_test, y_test, feature_names = joblib.load(os.path.join(data_path, "test.pkl"))

    # üîÅ Aplanar entradas si est√°n expandidas (para audio)
    if len(x_train.shape) > 2:
        x_train = x_train.reshape(x_train.shape[0], -1)
        x_test = x_test.reshape(x_test.shape[0], -1)

    # üè∑Ô∏è Cargar nombres de clases (emociones)
    class_labels_path = os.path.join(data_path, "class_labels.npy")
    if os.path.exists(class_labels_path):
        class_names = np.load(class_labels_path, allow_pickle=True)
    else:
        raise FileNotFoundError("‚ùå No se encontr√≥ el archivo class_labels.npy con los nombres de las emociones.")

    # üîÑ Decodificar etiquetas One-Hot a √≠ndices
    y_train_labels = np.argmax(y_train, axis=1)
    y_test_labels = np.argmax(y_test, axis=1)

    # Crear el modelo CNN
    model = Sequential()
    model.add(Conv1D(32, 3, activation='relu', input_shape=(x_train.shape[1], 1)))
    model.add(MaxPooling1D(2))
    model.add(Conv1D(64, 3, activation='relu'))
    model.add(MaxPooling1D(2))
    model.add(Conv1D(128, 3, activation='relu'))  # Capa adicional
    model.add(MaxPooling1D(2))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.6))  # Aumentar dropout
    model.add(Dense(len(class_names), activation='softmax'))  # Cambiado a n√∫mero de clases

    # Resumen del modelo
    model.summary()

    # Compilar el modelo
    model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])

    # Definir callbacks
    early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)
    lr_reduction = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)

    # Entrenar el modelo
    history = model.fit(x_train, y_train,  # Aseg√∫rate de que y_train est√© en la forma correcta
                        validation_data=(x_test, y_test),
                        epochs=epochs,
                        batch_size=batch_size,
                        verbose=1,
                        callbacks=[early_stopping, lr_reduction])

    # Evaluar el modelo
    x_test_reshaped = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)
    y_pred = model.predict(x_test_reshaped)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_test_classes = np.argmax(y_test, axis=1)

    # Evaluaci√≥n del modelo
    accuracy = model.evaluate(x_test_reshaped, y_test)[1] * 100
    print(f"Accuracy of our model on test data: {accuracy:.2f} %")

    # Visualizaci√≥n de la p√©rdida y precisi√≥n
    grafico_perdida(history)

    # Retornar el modelo y el historial
    return model, history