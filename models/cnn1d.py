# -*- coding: utf-8 -*-
"""CNN1D.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FQjyZAhT42ZMtXo4Y_Fn4mvAGo6e6oH6
"""



"""nuevo modelo CNN 1D"""

# Importaci√≥n de librer√≠as necesarias
import os
import joblib
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam

def grafico_perdida(history):
    plt.figure(figsize=(12, 4))

    # P√©rdida
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='P√©rdida de Entrenamiento')
    plt.plot(history.history['val_loss'], label='P√©rdida de Validaci√≥n')
    plt.title('P√©rdida durante el Entrenamiento')
    plt.xlabel('√âpocas')
    plt.ylabel('P√©rdida')
    plt.legend()

    # Precisi√≥n
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Precisi√≥n de Entrenamiento')
    plt.plot(history.history['val_accuracy'], label='Precisi√≥n de Validaci√≥n')
    plt.title('Precisi√≥n durante el Entrenamiento')
    plt.xlabel('√âpocas')
    plt.ylabel('Precisi√≥n')
    plt.legend()

    plt.tight_layout()
    plt.show()


def modelo_cnn_1D(data_path="src/", models_path="models/", epochs=50, batch_size=32):
    # üì¶ Cargar datos de entrenamiento y prueba
    x_train, y_train, feature_names = joblib.load(os.path.join(data_path, "train.pkl"))
    x_test, y_test, feature_names = joblib.load(os.path.join(data_path, "test.pkl"))

    # üîÅ Aplanar entradas si est√°n expandidas (para audio)
    if len(x_train.shape) > 2:
        x_train = x_train.reshape(x_train.shape[0], -1)
        x_test = x_test.reshape(x_test.shape[0], -1)

    # Add channel dimension for CNN 1D
    x_train = np.expand_dims(x_train, axis=-1)
    x_test = np.expand_dims(x_test, axis=-1)


    # üè∑Ô∏è Cargar nombres de clases (emociones)
    class_labels_path = os.path.join(data_path, "class_labels.npy")
    if os.path.exists(class_labels_path):
        class_names = np.load(class_labels_path, allow_pickle=True)
    else:
        raise FileNotFoundError("‚ùå No se encontr√≥ el archivo class_labels.npy con los nombres de las emociones.")

    # üîÑ Decodificar etiquetas One-Hot a √≠ndices
    y_train_labels = np.argmax(y_train, axis=1)
    y_test_labels = np.argmax(y_test, axis=1)

    # Crear el modelo CNN
    model = Sequential()
    model.add(Input(shape=(x_train.shape[1], 1))) # Corrected input shape
    model.add(Conv1D(32, 3, activation='relu'))
    model.add(MaxPooling1D(2))
    model.add(Conv1D(64, 3, activation='relu'))
    model.add(MaxPooling1D(2))
    model.add(Conv1D(128, 3, activation='relu'))  # Capa adicional
    model.add(MaxPooling1D(2))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.6))  # Aumentar dropout
    model.add(Dense(len(class_names), activation='softmax'))  # Cambiado a n√∫mero de clases

    # Resumen del modelo
    model.summary()

    # Compilar el modelo
    model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])

    # Definir callbacks
    early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)
    lr_reduction = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)

    # Entrenar el modelo
    history = model.fit(x_train, y_train,  # Aseg√∫rate de que y_train est√© en la forma correcta
                        validation_data=(x_test, y_test),
                        epochs=epochs,
                        batch_size=batch_size,
                        verbose=1,
                        callbacks=[early_stopping, lr_reduction])


    # Visualizaci√≥n de la p√©rdida y precisi√≥n
    grafico_perdida(history)
    
    # üíæ Guardar modelo
    model_path = os.path.join(models_path, "cnn1d.keras")
    model.save(model_path)
    print(f"üì¶ Modelo CNN1D guardado en: {model_path}")
    
    # Evaluate the model
    accuracy = model.evaluate(x_test, y_test)[1] * 100 # Use x_test directly
    print(f"Accuracy of our model on test data: {accuracy:.2f} %")

    # üß™ Evaluaci√≥n en test
    y_pred_probs = model.predict(x_test)
    y_pred_labels = np.argmax(y_pred_probs, axis=1)
    #y_test_labels = np.argmax(y_test, axis=1) # Already created y_test_labels earlier

    print("üìà Evaluaci√≥n final en conjunto de prueba:")
    metrics_values(y_test_labels, y_pred_labels, class_names)

    return model, x_test, feature_names # Return model, x_test, and feature_names
