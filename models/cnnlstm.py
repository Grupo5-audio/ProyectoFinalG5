# -*- coding: utf-8 -*-
"""CNNLSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uiWy1r13qn9gQeDUPRhSc44BO75ScPf2

**CNN y LSTM sin L2** Para la tarea de detección de emociones en la voz, una combinación de CNN y LSTM podría ser la más efectiva. Las CNN pueden extraer características importantes de las señales de audio, mientras que las LSTM pueden manejar la secuencialidad de los datos de audio. Implementación Si se decide implementar una red combinada, se puedes usar una arquitectura donde las capas convolucionales procesen las características de audio y luego pasen a capas LSTM para capturar la dinámica temporal de las emociones. LSTM (Long Short-Term Memory) es un tipo de red neuronal recurrente (RNN) diseñada para aprender secuencias y patrones en datos que tienen dependencias temporales. A continuación, sus características y funcionamiento:

Características de LSTM Memoria a Largo Plazo:

A diferencia de las RNN tradicionales, que pueden tener problemas para recordar información a largo plazo (debido al problema del desvanecimiento y explosión del gradiente), las LSTM están diseñadas para recordar información durante períodos prolongados.
Aplicaciones de LSTM Procesamiento de Lenguaje Natural:
Traducción automática, análisis de sentimientos, generación de texto. Reconocimiento de Voz: Modelado de secuencias de audio.
Predicción de Series Temporales: Análisis financiero, pronóstico de demanda.
"""

# sin l2
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, TimeDistributed, Reshape, BatchNormalization
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau  # Importar ReduceLROnPlateau
from keras.optimizers import Adam
from keras.utils import to_categorical
import tensorflow as tf
from tensorflow.keras.regularizers import l2  # Importar la función de regularización L2
from sklearn.metrics import accuracy_score, f1_score
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
import os
import joblib
import numpy as np



def grafico_perdida(history):
    plt.figure(figsize=(12, 4))

    # Pérdida
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Pérdida de Entrenamiento')
    plt.plot(history.history['val_loss'], label='Pérdida de Validación')
    plt.title('Pérdida durante el Entrenamiento')
    plt.xlabel('Épocas')
    plt.ylabel('Pérdida')
    plt.legend()

    # Precisión
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Precisión de Entrenamiento')
    plt.plot(history.history['val_accuracy'], label='Precisión de Validación')
    plt.title('Precisión durante el Entrenamiento')
    plt.xlabel('Épocas')
    plt.ylabel('Precisión')
    plt.legend()

    plt.tight_layout()
    plt.show()


def entrenar_modelo_cnn_lstm(data_path="src/", models_path="models/", epochs=50, batch_size=32):
    # Cargar datos de entrenamiento y prueba
    x_train, y_train, feature_names = joblib.load(os.path.join(data_path, "train.pkl"))
    x_test, y_test, feature_names = joblib.load(os.path.join(data_path, "test.pkl"))

    # Aplanar entradas si están expandidas (para audio)
    if len(x_train.shape) > 2:
        x_train = x_train.reshape(x_train.shape[0], -1)
        x_test = x_test.reshape(x_test.shape[0], -1)

    # Cargar nombres de clases (emociones)
    class_labels_path = os.path.join(data_path, "class_labels.npy")
    if os.path.exists(class_labels_path):
        class_names = np.load(class_labels_path, allow_pickle=True)
    else:
        raise FileNotFoundError("❌ No se encontró el archivo class_labels.npy con los nombres de las emociones.")

    # Decodificar etiquetas One-Hot a índices
    y_train_labels = np.argmax(y_train, axis=1)
    y_test_labels = np.argmax(y_test, axis=1)

    # Ajustar las dimensiones para el modelo
    x_train = np.expand_dims(x_train, axis=2)  # Asegúrate que x_train tiene forma (n_samples, 364, 1)
    x_test = np.expand_dims(x_test, axis=2)    # Asegúrate que x_test tiene forma (n_samples, 364, 1)

    # Verificar las formas de los datos
    print(f"x_test shape: {x_test.shape}")  # Debe ser (n_samples, 364, 1)
    print(f"y_test shape: {y_test.shape}")    # Debe ser (n_samples, num_classes)

    # Si y_test no está en formato one-hot, conviértelo
    if len(y_test.shape) == 1:  # Si es un vector
        num_classes = np.max(y_test) + 1  # Asumiendo que las clases son 0 a num_classes-1
        y_test = to_categorical(y_test, num_classes)

    # Definir el modelo
    model = Sequential()
    model.add(Reshape((x_train.shape[1], 1), input_shape=(x_train.shape[1],)))
    model.add(Conv1D(512, kernel_size=5, activation='relu'))
    model.add(BatchNormalization())
    model.add(MaxPooling1D(pool_size=5))
    model.add(Dropout(0.3))
    model.add(Conv1D(256, kernel_size=5, activation='relu'))
    model.add(BatchNormalization())
    model.add(MaxPooling1D(pool_size=5))
    model.add(Dropout(0.3))
    model.add(TimeDistributed(Flatten()))
    model.add(LSTM(200, return_sequences=True))
    model.add(LSTM(200, return_sequences=True))  # Capa adicional
    model.add(LSTM(200, return_sequences=False))
    model.add(Dropout(0.5))
    model.add(Dense(y_train.shape[1], activation='softmax'))
    model.summary()

    # Compilar el modelo con una tasa de aprendizaje ajustada
    optimizer = Adam(learning_rate=0.0001)  # Tasa de aprendizaje más baja
    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

    # Definir Callbacks
    checkpoint = ModelCheckpoint(os.path.join(models_path, "best_model.keras"), monitor='val_accuracy', save_best_only=True)
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)

    # Entrenar el modelo
    history = model.fit(x_train, y_train,
                        batch_size=batch_size,
                        epochs=epochs,
                        validation_data=(x_test, y_test),
                        callbacks=[checkpoint, early_stopping, reduce_lr])

    # Evaluación del modelo
    accuracy = model.evaluate(x_test, y_test)[1] * 100
    print(f"Accuracy of our model on test data: {accuracy:.2f} %")

    # Visualización de la pérdida y precisión
    grafico_perdida(history)

    return model, history  # Retornar el modelo y el historial